import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import plotly.express as px
from dateutil.relativedelta import relativedelta
from sklearn.ensemble import RandomForestRegressor


# =========================
# 1) Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
# =========================
st.set_page_config(page_title="Ù…Ø±ÙƒØ² Ø°ÙƒØ§Ø¡ Ø§Ù„Ù‚ÙˆÙ‰ Ø§Ù„Ø¹Ø§Ù…Ù„Ø©", layout="wide")

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700;900&display=swap');
html, body, [class*="css"] { font-family: 'Tajawal', sans-serif; text-align: right; }
.stApp { background: radial-gradient(circle at top right, #1E293B, #0F172A, #020617); }
h1 { 
  background: linear-gradient(to left, #F8FAFC, #00F5FF);
  -webkit-background-clip: text; -webkit-text-fill-color: transparent;
  font-weight: 900 !important; font-size: 3.0rem !important;
  text-align: center !important;
}
.small-muted { color: #94A3B8; font-size: 0.95rem; }
.welcome-card {
  background: rgba(255, 255, 255, 0.03);
  backdrop-filter: blur(25px);
  border: 1px solid rgba(0, 245, 255, 0.15);
  padding: 50px 35px;
  border-radius: 30px;
  text-align: center;
  margin: 55px auto 20px auto;
  max-width: 980px;
  box-shadow: 0 25px 50px rgba(0,0,0,0.6);
}
.sidebar-signature{
  padding-top: 14px;
  border-top: 1px solid rgba(0, 245, 255, 0.1);
  text-align: center;
  margin-top: 14px;
}
.rec-box { 
  background: rgba(0, 245, 255, 0.07); 
  padding: 16px; border-radius: 14px; 
  border-right: 5px solid #00F5FF; margin-bottom: 12px; 
  color: #F8FAFC; font-weight: 600;
}
</style>
""", unsafe_allow_html=True)

px.defaults.template = "plotly_dark"


# =========================
# 2) ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# =========================
@st.cache_data
def load_actual_data():
    base = os.path.dirname(__file__)
    path = os.path.join(base, "Resigned Report Date Range.xlsx")
    df = pd.read_excel(path, engine="openpyxl")
    df["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"] = pd.to_datetime(df["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"], errors="coerce", dayfirst=True)
    return df

@st.cache_data
def load_forecast_file():
    base = os.path.dirname(__file__)
    path = os.path.join(base, "ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.xlsx")
    return pd.read_excel(path, engine="openpyxl")

try:
    df = load_actual_data()
    error = None
except Exception as e:
    df = None
    error = str(e)

try:
    forecast_file_df = load_forecast_file()
except Exception:
    forecast_file_df = None


# =========================
# 3) ØªØ¬Ù‡ÙŠØ² ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø³Ù†ÙˆÙŠ (Ù…ØµØ¯Ø± Ø«Ø§Ø¨Øª)
# =========================
def get_file_yearly_forecast(fdf: pd.DataFrame) -> pd.DataFrame:
    if fdf is None or fdf.empty:
        return pd.DataFrame()

    needed = {"Ø§Ù„Ø³Ù†Ø©", "Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹"}
    if not needed.issubset(set(fdf.columns)):
        return pd.DataFrame()

    out = (fdf.groupby("Ø§Ù„Ø³Ù†Ø©", as_index=False)["Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹"]
           .sum()
           .rename(columns={"Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹": "Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"}))
    out["Ø§Ù„Ø³Ù†Ø©"] = pd.to_numeric(out["Ø§Ù„Ø³Ù†Ø©"], errors="coerce").astype("Int64")
    out = out.dropna(subset=["Ø§Ù„Ø³Ù†Ø©"]).copy()
    out["Ø§Ù„Ø³Ù†Ø©"] = out["Ø§Ù„Ø³Ù†Ø©"].astype(int)
    out["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"] = pd.to_numeric(out["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"], errors="coerce").fillna(0).round().astype(int)
    return out.sort_values("Ø§Ù„Ø³Ù†Ø©").reset_index(drop=True)

file_yearly_fc = get_file_yearly_forecast(forecast_file_df)


# =========================
# 4) Ø£Ø¯ÙˆØ§Øª Parsing + Filters
# =========================
AR_MONTHS = {
    "ÙŠÙ†Ø§ÙŠØ±": 1, "ÙØ¨Ø±Ø§ÙŠØ±": 2, "Ù…Ø§Ø±Ø³": 3, "Ø§Ø¨Ø±ÙŠÙ„": 4, "Ø£Ø¨Ø±ÙŠÙ„": 4,
    "Ù…Ø§ÙŠÙˆ": 5, "ÙŠÙˆÙ†ÙŠÙˆ": 6, "ÙŠÙˆÙ„ÙŠÙˆ": 7, "Ø§ØºØ³Ø·Ø³": 8, "Ø£ØºØ³Ø·Ø³": 8,
    "Ø³Ø¨ØªÙ…Ø¨Ø±": 9, "Ø§ÙƒØªÙˆØ¨Ø±": 10, "Ø£ÙƒØªÙˆØ¨Ø±": 10, "Ù†ÙˆÙÙ…Ø¨Ø±": 11, "Ø¯ÙŠØ³Ù…Ø¨Ø±": 12
}

def norm_ar(s: str) -> str:
    s = (s or "").strip().lower()
    s = s.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    s = s.replace("Ø©", "Ù‡").replace("Ù‰", "ÙŠ")
    s = re.sub(r"\s+", " ", s)
    return s

def get_ref_today(dff: pd.DataFrame) -> pd.Timestamp:
    mx = dff["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"].max()
    return pd.Timestamp.today().normalize() if pd.isna(mx) else pd.Timestamp(mx).normalize()

def parse_date_any(s: str):
    s = (s or "").strip()
    if not s:
        return pd.NaT
    return pd.to_datetime(s, dayfirst=True, errors="coerce")

def extract_between_dates(qn: str):
    m = re.search(r"Ù…Ù†\s+(.+?)\s+(?:Ø§Ù„Ù‰|Ø¥Ù„Ù‰)\s+(.+)", qn)
    if not m:
        return None
    d1 = parse_date_any(m.group(1))
    d2 = parse_date_any(m.group(2))
    if pd.isna(d1) or pd.isna(d2):
        return None
    start = min(pd.Timestamp(d1).normalize(), pd.Timestamp(d2).normalize())
    end = max(pd.Timestamp(d1).normalize(), pd.Timestamp(d2).normalize())
    return start, end

def extract_relative_range(qn: str, ref_today: pd.Timestamp):
    m = re.search(r"(?:Ø§Ø®Ø±|Ø¢Ø®Ø±)\s+(\d+)\s*(ÙŠÙˆÙ…|Ø§ÙŠØ§Ù…|Ø§Ø³Ø¨ÙˆØ¹|Ø§Ø³Ø§Ø¨ÙŠØ¹|Ø´Ù‡Ø±|Ø´Ù‡ÙˆØ±|Ø§Ø´Ù‡Ø±|Ø³Ù†Ù‡|Ø³Ù†ÙˆØ§Øª)", qn)
    if m:
        n = int(m.group(1))
        unit = m.group(2)
        if "ÙŠÙˆÙ…" in unit:
            start = ref_today - pd.Timedelta(days=n)
        elif "Ø§Ø³Ø¨ÙˆØ¹" in unit:
            start = ref_today - pd.Timedelta(weeks=n)
        elif "Ø´Ù‡Ø±" in unit or "Ø§Ø´Ù‡Ø±" in unit or "Ø´Ù‡ÙˆØ±" in unit:
            start = pd.Timestamp(ref_today - relativedelta(months=n)).normalize()
        else:
            start = pd.Timestamp(ref_today - relativedelta(years=n)).normalize()
        return start, ref_today

    if "Ø§Ø®Ø± Ø´Ù‡Ø±" in qn or "Ø¢Ø®Ø± Ø´Ù‡Ø±" in qn:
        start = pd.Timestamp(ref_today - relativedelta(months=1)).normalize()
        return start, ref_today

    if "Ø§Ø®Ø± Ø§Ø³Ø¨ÙˆØ¹" in qn or "Ø¢Ø®Ø± Ø§Ø³Ø¨ÙˆØ¹" in qn:
        start = ref_today - pd.Timedelta(weeks=1)
        return start, ref_today

    return None

def extract_month_year(qn: str):
    year = None
    m = re.search(r"(20\d{2})", qn)
    if m:
        year = int(m.group(1))

    month = None
    for name, num in AR_MONTHS.items():
        if norm_ar(name) in qn:
            month = num
            break

    if year and month:
        start = pd.Timestamp(year=year, month=month, day=1)
        end = (start + relativedelta(months=1)) - pd.Timedelta(days=1)
        return start, end

    if year and not month:
        start = pd.Timestamp(year=year, month=1, day=1)
        end = pd.Timestamp(year=year, month=12, day=31)
        return start, end

    return None

def get_date_range_from_question(q: str, ref_today: pd.Timestamp):
    qn = norm_ar(q)
    r = extract_between_dates(qn)
    if r: return r
    r = extract_relative_range(qn, ref_today)
    if r: return r
    r = extract_month_year(qn)
    if r: return r
    return None

def apply_sidebar_filters(df_in, date_range, dept_sel, nat_sel):
    dff = df_in.dropna(subset=["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"]).copy()
    start = pd.to_datetime(date_range[0])
    end = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
    dff = dff[(dff["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"] >= start) & (dff["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"] <= end)]

    if dept_sel:
        dff = dff[dff["Ø§Ù„Ø¬Ù‡Ø©"].astype(str).isin(dept_sel)]
    if nat_sel:
        dff = dff[dff["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].astype(str).isin(nat_sel)]
    return dff

def apply_question_entity_filters(dff: pd.DataFrame, q: str):
    qn = norm_ar(q)

    m = re.search(r"(?:Ø¬Ù‡Ù‡|Ø¬Ù‡Ø©|Ø§Ù„Ø¬Ù‡Ù‡|Ø§Ù„Ø¬Ù‡Ø©)\s*[:ï¼š]\s*(.+)", qn)
    if m:
        val = m.group(1).strip()[:80]
        dff = dff[dff["Ø§Ù„Ø¬Ù‡Ø©"].astype(str).str.contains(val, na=False)]

    m = re.search(r"(?:Ø¬Ù†Ø³ÙŠÙ‡|Ø¬Ù†Ø³ÙŠØ©|Ø§Ù„Ø¬Ù†Ø³ÙŠØ©|Ø§Ù„Ø¬Ù†Ø³ÙŠÙ‡)\s*[:ï¼š]\s*(.+)", qn)
    if m:
        val = m.group(1).strip()[:80]
        dff = dff[dff["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].astype(str).str.contains(val, na=False)]

    return dff


# =========================
# 5) Ø³Ù„Ø³Ù„Ø© Ø²Ù…Ù†ÙŠØ© + ØªÙˆÙ‚Ø¹ (ÙŠÙˆÙ…ÙŠ/Ø´Ù‡Ø±ÙŠ) Ø¯Ø§Ø®Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# =========================
def make_series(dff: pd.DataFrame, freq="D"):
    if freq == "M":
        freq = "ME"
    s = (dff.dropna(subset=["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"])
            .set_index("ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©")
            .resample(freq)
            .size()
            .rename("y"))
    if freq == "D":
        s = s.asfreq("D", fill_value=0)
    return s

def make_features(series: pd.Series, freq="D"):
    d = pd.DataFrame({"y": series})
    if freq == "D":
        d["dow"] = d.index.dayofweek
        d["dom"] = d.index.day
        d["month"] = d.index.month
        d["is_weekend"] = (d["dow"] >= 4).astype(int)
        use_lags = (1, 7, 14, 28)
    else:
        d["month"] = d.index.month
        d["quarter"] = d.index.quarter
        use_lags = (1, 2, 3, 6)

    for lag in use_lags:
        d[f"lag_{lag}"] = d["y"].shift(lag)

    d = d.dropna()
    X = d.drop(columns=["y"])
    y = d["y"]
    return X, y, use_lags

def forecast_time(dff: pd.DataFrame, steps=30, freq="D"):
    s = make_series(dff, freq=("ME" if freq == "M" else "D"))

    min_need = 60 if freq == "D" else 12
    if len(s) < min_need:
        base = float(s.tail(30).mean()) if freq == "D" else float(s.tail(6).mean())
        if np.isnan(base):
            base = 0.0
        base_i = int(round(base))
        future_idx = (
            pd.date_range(s.index.max() + pd.Timedelta(days=1), periods=steps, freq="D")
            if freq == "D"
            else pd.date_range(s.index.max() + pd.offsets.MonthBegin(1), periods=steps, freq="MS")
        )
        return pd.DataFrame({"Ø§Ù„ØªØ§Ø±ÙŠØ®": future_idx, "Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©": [max(0, base_i)] * len(future_idx)})

    X, y, use_lags = make_features(s, freq=("D" if freq == "D" else "M"))
    model = RandomForestRegressor(n_estimators=450, random_state=42)
    model.fit(X, y)

    future_idx = (
        pd.date_range(s.index.max() + pd.Timedelta(days=1), periods=steps, freq="D")
        if freq == "D"
        else pd.date_range(s.index.max() + pd.offsets.MonthBegin(1), periods=steps, freq="MS")
    )

    s_ext = s.copy()
    preds = []

    for dt in future_idx:
        row = {}
        if freq == "D":
            row["dow"] = dt.dayofweek
            row["dom"] = dt.day
            row["month"] = dt.month
            row["is_weekend"] = int(dt.dayofweek >= 4)
        else:
            row["month"] = dt.month
            row["quarter"] = dt.quarter

        for lag in use_lags:
            row[f"lag_{lag}"] = float(s_ext.iloc[-lag])

        yhat = float(model.predict(pd.DataFrame([row]))[0])
        yhat = max(0.0, yhat)
        preds.append(yhat)
        s_ext.loc[dt] = yhat

    return pd.DataFrame({"Ø§Ù„ØªØ§Ø±ÙŠØ®": future_idx, "Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©": np.round(preds).astype(int)})


# =========================
# 6) ÙØ¹Ù„ÙŠ Ø³Ù†ÙˆÙŠ + Ù…Ù‚Ø§Ø±Ù†Ø© ÙØ¹Ù„ÙŠÃ—Ù…ØªÙˆÙ‚Ø¹ (Ù…Ù„Ù)
# =========================
def actual_yearly_counts(dff: pd.DataFrame) -> pd.DataFrame:
    x = dff.dropna(subset=["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"]).copy()
    x["Ø§Ù„Ø³Ù†Ø©"] = x["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"].dt.year
    y = x.groupby("Ø§Ù„Ø³Ù†Ø©").size().reset_index(name="Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©").sort_values("Ø§Ù„Ø³Ù†Ø©").reset_index(drop=True)
    y["Ø§Ù„Ø³Ù†Ø©"] = y["Ø§Ù„Ø³Ù†Ø©"].astype(int)
    return y

def compare_actual_vs_file_forecast(actual_df: pd.DataFrame, file_fc: pd.DataFrame) -> pd.DataFrame:
    if actual_df is None or actual_df.empty:
        return pd.DataFrame()
    out = actual_df.merge(file_fc, on="Ø§Ù„Ø³Ù†Ø©", how="left")
    out["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"] = out["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"].fillna(0).astype(int)
    out["Ø§Ù„ÙØ±Ù‚ (ÙØ¹Ù„ÙŠ-Ù…ØªÙˆÙ‚Ø¹)"] = out["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©"] - out["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"]
    return out


# =========================
# 7) auto_chart (ÙŠØ±Ø¯ + ÙŠØ±Ø³Ù…) â€” Ø§Ù„Ø³Ù†ÙˆÙŠ Ù…Ù† Ø§Ù„Ù…Ù„Ù
# =========================
def auto_chart(dff_base: pd.DataFrame, q: str, top_n=10, sidebar_info=""):
    qn = norm_ar(q)
    ref_today = get_ref_today(dff_base)

    dff = apply_question_entity_filters(dff_base.copy(), q)

    dr = get_date_range_from_question(q, ref_today)
    if dr:
        start, end = dr
        end_inclusive = end + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
        dff = dff[(dff["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"] >= start) & (dff["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"] <= end_inclusive)]
        range_text = f"ğŸ“… Ø§Ù„ÙØªØ±Ø©: Ù…Ù† **{start.date()}** Ø¥Ù„Ù‰ **{end.date()}** (Ù…Ø±Ø¬Ø¹: {ref_today.date()})"
    else:
        range_text = f"ğŸ“… Ø§Ù„ÙØªØ±Ø©: Ø­Ø³Ø¨ ÙÙ„Ø§ØªØ± Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø± (Ù…Ø±Ø¬Ø¹: {ref_today.date()})"

    def footer(msg: str):
        parts = [msg, range_text]
        if sidebar_info:
            parts.append(sidebar_info)
        return "\n\n".join(parts)

    if dff.empty:
        return footer("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø³Ø¤Ø§Ù„/Ø§Ù„ÙÙ„Ø§ØªØ±."), None, None

    # (A) Ø£Ø­Ø¯Ø« Ø³Ø¬Ù„Ø§Øª Ø¬Ø¯ÙˆÙ„ (Ø¨Ø¯ÙˆÙ† Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø©)
    if ("Ø§Ø­Ø¯Ø«" in qn or "Ø§Ø®Ø±" in qn or "latest" in qn) and ("Ø¬Ø¯ÙˆÙ„" in qn or "table" in qn or "Ø³Ø¬Ù„Ø§Øª" in qn):
        wanted_cols = ["Ø§Ù„Ø¬Ù‡Ø©", "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", "ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©", "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø©"]
        safe_cols = [c for c in wanted_cols if c in dff.columns]
        tbl = dff.sort_values("ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©", ascending=False).head(10)[safe_cols]
        return footer("ğŸ•’ Ø£Ø­Ø¯Ø« 10 Ø³Ø¬Ù„Ø§Øª:"), None, tbl

    # (B) Ø¹Ø¯Ø¯/Ø¥Ø¬Ù…Ø§Ù„ÙŠ
    if any(k in qn for k in ["ÙƒÙ…", "Ø¹Ø¯Ø¯", "Ø§Ø¬Ù…Ø§Ù„ÙŠ", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ", "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹", "total"]):
        return footer(f"ğŸ“Š **Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª = {len(dff):,}**"), None, None

    # (C) ØªÙˆØ²ÙŠØ¹
    if any(k in qn for k in ["ØªÙˆØ²ÙŠØ¹", "Ù†Ø³Ø¨", "Ù†Ø³Ø¨Ø©", "pie", "Ø¯Ø§Ø¦Ø±Ù‡", "Ø¯Ø§Ø¦Ø±Ø©"]):
        if "Ø¬Ù†Ø³" in qn:
            vc = dff["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].value_counts().head(top_n).rename_axis("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
            fig = px.pie(vc, values="Ø§Ù„Ø¹Ø¯Ø¯", names="Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", hole=0.45, title=f"ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª (Top {top_n})")
            fig.update_traces(textinfo="percent+label")
            return footer("ğŸŒ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª"), fig, vc

        if any(k in qn for k in ["Ø¬Ù‡Ù‡", "Ø¬Ù‡Ø©", "Ø§Ù„Ø¬Ù‡Ø©", "Ø§Ø¯Ø§Ø±Ù‡", "Ø¥Ø¯Ø§Ø±Ø©"]):
            vc = dff["Ø§Ù„Ø¬Ù‡Ø©"].value_counts().head(top_n).rename_axis("Ø§Ù„Ø¬Ù‡Ø©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
            fig = px.pie(vc, values="Ø§Ù„Ø¹Ø¯Ø¯", names="Ø§Ù„Ø¬Ù‡Ø©", hole=0.45, title=f"ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù‡Ø§Øª (Top {top_n})")
            fig.update_traces(textinfo="percent+label")
            return footer("ğŸ¢ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù‡Ø§Øª"), fig, vc

    # (D) Ø£ÙƒØ«Ø± / Ø£Ù‚Ù„
    if any(k in qn for k in ["Ø§ÙƒØ«Ø±", "Ø§Ù„Ø£ÙƒØ«Ø±", "Ø§Ø¹Ù„Ù‰", "Ø£Ø¹Ù„Ù‰", "top", "Ø§ÙƒØ¨Ø±", "Ø£ÙƒØ¨Ø±"]):
        if "Ø¬Ù†Ø³" in qn:
            vc = dff["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].value_counts().head(top_n).rename_axis("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
            fig = px.bar(vc, x="Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", y="Ø§Ù„Ø¹Ø¯Ø¯", text_auto=True, title=f"Ø£ÙƒØ«Ø± Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª (Top {top_n})")
            return footer("ğŸŒ Ø£ÙƒØ«Ø± Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª"), fig, vc

        vc = dff["Ø§Ù„Ø¬Ù‡Ø©"].value_counts().head(top_n).rename_axis("Ø§Ù„Ø¬Ù‡Ø©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
        fig = px.bar(vc, x="Ø§Ù„Ø¬Ù‡Ø©", y="Ø§Ù„Ø¹Ø¯Ø¯", text_auto=True, title=f"Ø£ÙƒØ«Ø± Ø§Ù„Ø¬Ù‡Ø§Øª (Top {top_n})")
        fig.update_layout(xaxis_tickangle=-35)
        return footer("ğŸ¢ Ø£ÙƒØ«Ø± Ø§Ù„Ø¬Ù‡Ø§Øª"), fig, vc

    if any(k in qn for k in ["Ø§Ù‚Ù„", "Ø§Ù„Ø£Ù‚Ù„", "Ø§Ø¯Ù†Ù‰", "Ø£Ø¯Ù†Ù‰", "bottom"]):
        if "Ø¬Ù†Ø³" in qn:
            vc = dff["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].value_counts().tail(top_n).rename_axis("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
            fig = px.bar(vc, x="Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", y="Ø§Ù„Ø¹Ø¯Ø¯", text_auto=True, title=f"Ø£Ù‚Ù„ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª (Bottom {top_n})")
            return footer("ğŸ“‰ Ø£Ù‚Ù„ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª"), fig, vc

        vc = dff["Ø§Ù„Ø¬Ù‡Ø©"].value_counts().tail(top_n).rename_axis("Ø§Ù„Ø¬Ù‡Ø©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
        fig = px.bar(vc, x="Ø§Ù„Ø¬Ù‡Ø©", y="Ø§Ù„Ø¹Ø¯Ø¯", text_auto=True, title=f"Ø£Ù‚Ù„ Ø§Ù„Ø¬Ù‡Ø§Øª (Bottom {top_n})")
        fig.update_layout(xaxis_tickangle=-35)
        return footer("ğŸ“‰ Ø£Ù‚Ù„ Ø§Ù„Ø¬Ù‡Ø§Øª"), fig, vc

    # (E) ØªØ±Ù†Ø¯
    if any(k in qn for k in ["ØªØ±Ù†Ø¯", "Ø§ØªØ¬Ø§Ù‡", "Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†", "trend", "line", "Ø®Ø·ÙŠ", "Ø®Ø·"]):
        monthly = any(k in qn for k in ["Ø´Ù‡Ø±ÙŠ", "Ø´Ù‡Ø±"])
        freq = "M" if monthly else "D"
        ts = make_series(dff, freq=freq).reset_index()
        ts.columns = ["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø¹Ø¯Ø¯"]
        fig = px.line(ts, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="Ø§Ù„Ø¹Ø¯Ø¯", markers=True, title=("Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø´Ù‡Ø±ÙŠÙ‹Ø§" if monthly else "Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ÙŠÙˆÙ…ÙŠÙ‹Ø§"))
        return footer("ğŸ“ˆ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†"), fig, ts.tail(200)

    # (F) ØªÙˆÙ‚Ø¹ â€” Ø§Ù„Ø³Ù†ÙˆÙŠ Ù…Ù† Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹ (ØªÙˆØ­ÙŠØ¯)
    if any(k in qn for k in ["ØªÙˆÙ‚Ø¹", "ÙŠØªÙˆÙ‚Ø¹", "ØªÙ†Ø¨Ø¤", "ÙŠØªÙ†Ø¨Ø§", "Ø§Ù„Ù‚Ø§Ø¯Ù…", "Ø§Ù„Ø¬Ø§ÙŠ"]):
        years = sorted({int(y) for y in re.findall(r"(20\d{2})", qn)})

        # Ø¥Ø°Ø§ Ø°ÙƒØ± Ø³Ù†Ø©/Ø³Ù†ÙˆØ§Øª: Ù†Ø¬ÙŠØ¨ Ù…Ù† Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹ (Ù†ÙØ³ Ø§Ù„ÙŠØ³Ø§Ø±)
        if years:
            if not file_yearly_fc.empty:
                preds = file_yearly_fc[file_yearly_fc["Ø§Ù„Ø³Ù†Ø©"].isin(years)].copy()
                if not preds.empty:
                    fig = px.bar(preds, x="Ø§Ù„Ø³Ù†Ø©", y="Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)", text_auto=True, title="ØªÙˆÙ‚Ø¹ Ø³Ù†ÙˆÙŠ (Ù…Ù† Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹)")
                    return footer(f"ğŸ”® ØªÙˆÙ‚Ø¹ Ø³Ù†ÙˆÙŠ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø³Ù†ÙˆØ§Øª: {', '.join(map(str, years))}"), fig, preds

            # fallback Ø¥Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…Ø§ ÙŠØºØ·ÙŠ Ø§Ù„Ø³Ù†ÙˆØ§Øª
            return footer("âš ï¸ Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ø³Ù†ÙˆØ§Øª."), None, file_yearly_fc

        # Ø´Ù‡Ø±ÙŠ
        if any(k in qn for k in ["Ø´Ù‡Ø±ÙŠ", "Ø´Ù‡Ø±", "Ø§Ø´Ù‡Ø±", "Ø´Ù‡ÙˆØ±"]):
            m = re.search(r"(\d+)\s*(Ø´Ù‡Ø±|Ø§Ø´Ù‡Ø±|Ø´Ù‡ÙˆØ±)", qn)
            steps = int(m.group(1)) if m else 6
            fc = forecast_time(dff, steps=steps, freq="M")
            fig = px.bar(fc, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", text_auto=True, title=f"ØªÙˆÙ‚Ø¹ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª ({steps} Ø£Ø´Ù‡Ø±)")
            return footer("ğŸ”® ØªÙˆÙ‚Ø¹ Ø´Ù‡Ø±ÙŠ"), fig, fc

        # ÙŠÙˆÙ…ÙŠ
        m = re.search(r"(\d+)\s*(ÙŠÙˆÙ…|Ø§ÙŠØ§Ù…)", qn)
        steps = int(m.group(1)) if m else 30
        fc = forecast_time(dff, steps=steps, freq="D")
        fig = px.area(fc, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", title=f"ØªÙˆÙ‚Ø¹ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª ({steps} ÙŠÙˆÙ…)")
        return footer("ğŸ”® ØªÙˆÙ‚Ø¹ ÙŠÙˆÙ…ÙŠ"), fig, fc

    # (G) fallback: Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ ØºÙŠØ± ÙˆØ§Ø¶Ø­ -> ØªØ±Ù†Ø¯ Ø´Ù‡Ø±ÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠ
    ts = make_series(dff, freq="M").reset_index()
    ts.columns = ["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø¹Ø¯Ø¯"]
    fig = px.line(ts, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="Ø§Ù„Ø¹Ø¯Ø¯", markers=True, title="ØªØ±Ù†Ø¯ Ø´Ù‡Ø±ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ)")
    msg = "â„¹ï¸ Ù…Ø§ ÙÙ‡Ù…Øª ØµÙŠØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ØŒ ÙØ¹Ø±Ù‘Ø¶Øª Ù„Ùƒ **ØªØ±Ù†Ø¯ Ø´Ù‡Ø±ÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠ**. Ø¬Ø±Ù‘Ø¨ÙŠ: (ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª) / (Ø£ÙƒØ«Ø± Ø¬Ù‡Ø©) / (ØªÙˆÙ‚Ø¹ 30 ÙŠÙˆÙ…) / (ØªÙˆÙ‚Ø¹ 2026)."
    return footer(msg), fig, ts.tail(200)


# =========================
# 8) Sidebar
# =========================
with st.sidebar:
    st.markdown("<h2 style='color:#00F5FF'>âš™ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…</h2>", unsafe_allow_html=True)

    if df is None:
        st.error(f"ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {error}")
        st.stop()

    df_clean = df.dropna(subset=["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"]).copy()
    if df_clean.empty:
        st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© ÙÙŠ Ø¹Ù…ÙˆØ¯ ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©.")
        st.stop()

    min_d = df_clean["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"].min().date()
    max_d = df_clean["ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø©"].max().date()

    date_range = st.date_input("ğŸ“… Ø§Ù„ÙØªØ±Ø©", value=(min_d, max_d), min_value=min_d, max_value=max_d)

    dept_list = sorted(df_clean["Ø§Ù„Ø¬Ù‡Ø©"].dropna().astype(str).unique().tolist())
    nat_list  = sorted(df_clean["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].dropna().astype(str).unique().tolist())

    dept_sel = st.multiselect("ğŸ¢ Ø§Ù„Ø¬Ù‡Ø©", dept_list, default=[])
    nat_sel  = st.multiselect("ğŸŒ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", nat_list, default=[])

    top_n = st.slider("Top N", 3, 20, 10)

    # ---- Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹ (Ø£Ø³ÙÙ„ ÙŠØ³Ø§Ø±)
    st.markdown("<div style='height: 28vh;'></div>", unsafe_allow_html=True)
    st.markdown("### ğŸ“„ Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹ (Ù„ÙˆØ­Ø¯Ù‡)")

    if file_yearly_fc.empty:
        st.info("Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ø£Ø¹Ù…Ø¯ØªÙ‡ ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")
    else:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (Ù…Ù† Ø§Ù„Ù…Ù„Ù)", int(file_yearly_fc["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"].sum()))
        fig_f = px.bar(file_yearly_fc, x="Ø§Ù„Ø³Ù†Ø©", y="Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)", text_auto=True, title="Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø³Ù†ÙˆÙŠ (Ù…Ù† Ø§Ù„Ù…Ù„Ù)")
        st.plotly_chart(fig_f, use_container_width=True)
        st.dataframe(file_yearly_fc, use_container_width=True)

    st.markdown("""
        <div class="sidebar-signature">
            <p style="color:#94A3B8;font-size:0.85rem;margin-bottom:4px;">Ø¥Ø¹Ø¯Ø§Ø¯</p>
            <p style="color:#00F5FF;font-size:1.5rem;font-weight:900;margin:0;">Ø¯Ù„Ø§Ù„ Ø­ÙƒÙ…ÙŠ</p>
            <p style="color:#475569;font-size:0.85rem;margin-top:4px;">dalal3021@gmail.com</p>
        </div>
    """, unsafe_allow_html=True)


# =========================
# 9) ÙÙ„Ø§ØªØ± Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø±
# =========================
dff_sidebar = apply_sidebar_filters(df, date_range, dept_sel, nat_sel)

sidebar_info = " | ".join([
    f"ğŸ›ï¸ ÙÙ„Ø§ØªØ± Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø±: Ø§Ù„ÙØªØ±Ø© ({date_range[0]} â†’ {date_range[1]})",
    "Ø§Ù„Ø¬Ù‡Ø©: " + (", ".join(dept_sel[:3]) + ("â€¦" if len(dept_sel) > 3 else "") if dept_sel else "ÙƒÙ„ Ø§Ù„Ø¬Ù‡Ø§Øª"),
    "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©: " + (", ".join(nat_sel[:3]) + ("â€¦" if len(nat_sel) > 3 else "") if nat_sel else "ÙƒÙ„ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª"),
])


# =========================
# 10) Tabs
# =========================
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©", "ğŸ“ˆ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª", "ğŸ”® Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª", "ğŸ¤– Ø§Ø³Ø£Ù„Ù†ÙŠ"])

with tab1:
    st.markdown("<h1>Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©</h1>", unsafe_allow_html=True)

    c1, c2, c3 = st.columns(3)
    c1.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª", f"{len(dff_sidebar):,}")
    c2.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù‡Ø§Øª", int(dff_sidebar["Ø§Ù„Ø¬Ù‡Ø©"].nunique()) if not dff_sidebar.empty else 0)
    c3.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª", int(dff_sidebar["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].nunique()) if not dff_sidebar.empty else 0)

    if dff_sidebar.empty:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ù…Ù† Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
    else:
        colA, colB = st.columns(2)
        with colA:
            nat_counts = dff_sidebar["Ø§Ù„Ø¬Ù†Ø³ÙŠØ©"].value_counts().head(top_n).rename_axis("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
            fig = px.pie(nat_counts, values="Ø§Ù„Ø¹Ø¯Ø¯", names="Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", hole=0.45, title=f"Top {top_n} Ø¬Ù†Ø³ÙŠØ§Øª")
            fig.update_traces(textinfo="percent+label")
            st.plotly_chart(fig, use_container_width=True)

        with colB:
            dept_counts = dff_sidebar["Ø§Ù„Ø¬Ù‡Ø©"].value_counts().head(top_n).rename_axis("Ø§Ù„Ø¬Ù‡Ø©").reset_index(name="Ø§Ù„Ø¹Ø¯Ø¯")
            fig = px.bar(dept_counts, x="Ø§Ù„Ø¬Ù‡Ø©", y="Ø§Ù„Ø¹Ø¯Ø¯", text_auto=True, title=f"Top {top_n} Ø¬Ù‡Ø§Øª")
            fig.update_layout(xaxis_tickangle=-35)
            st.plotly_chart(fig, use_container_width=True)

        top_dept = dff_sidebar["Ø§Ù„Ø¬Ù‡Ø©"].mode().iloc[0] if not dff_sidebar["Ø§Ù„Ø¬Ù‡Ø©"].mode().empty else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        st.markdown("### ğŸ’¡ ØªÙˆØµÙŠØ§Øª", unsafe_allow_html=True)
        st.markdown(f'<div class="rec-box">ğŸš€ ØªØ¹Ø²ÙŠØ² Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ø§Ø³ØªØ¨Ù‚Ø§Ø¡ Ø¯Ø§Ø®Ù„: {top_dept}</div>', unsafe_allow_html=True)
        st.markdown('<div class="rec-box">ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø© ÙˆØªØ­Ø³ÙŠÙ† ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ÙˆØ¸Ù</div>', unsafe_allow_html=True)

with tab2:
    st.markdown("<h1>Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª</h1>", unsafe_allow_html=True)

    if dff_sidebar.empty:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ù…Ù† Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
    else:
        gran = st.radio("Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©", ["ÙŠÙˆÙ…ÙŠ", "Ø´Ù‡Ø±ÙŠ"], horizontal=True)
        freq = "M" if gran == "Ø´Ù‡Ø±ÙŠ" else "D"
        ts = make_series(dff_sidebar, freq=freq).reset_index()
        ts.columns = ["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø¹Ø¯Ø¯"]
        fig = px.line(ts, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="Ø§Ù„Ø¹Ø¯Ø¯", markers=True, title=f"Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ({gran})")
        st.plotly_chart(fig, use_container_width=True)
        st.dataframe(ts.tail(120), use_container_width=True)

with tab3:
    st.markdown("<h1>Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª</h1>", unsafe_allow_html=True)

    if dff_sidebar.empty:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ù…Ù† Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
    else:
        mode = st.radio("Ù†ÙˆØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹", ["ÙŠÙˆÙ…ÙŠ (30 ÙŠÙˆÙ…)", "Ø´Ù‡Ø±ÙŠ (6 Ø£Ø´Ù‡Ø±)", "Ø³Ù†ÙˆÙŠ (Ù…Ù† Ø§Ù„Ù…Ù„Ù 2026-2028)", "Ù…Ù‚Ø§Ø±Ù†Ø© ÙØ¹Ù„ÙŠ Ã— Ù…ØªÙˆÙ‚Ø¹ (Ø³Ù†ÙˆÙŠ)"], horizontal=True)

        if mode.startswith("ÙŠÙˆÙ…ÙŠ"):
            fc = forecast_time(dff_sidebar, steps=30, freq="D")
            fig = px.area(fc, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", title="ØªÙˆÙ‚Ø¹ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª (30 ÙŠÙˆÙ…)")
            st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹", int(fc["Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©"].sum()))
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(fc, use_container_width=True)

        elif mode.startswith("Ø´Ù‡Ø±ÙŠ"):
            fc = forecast_time(dff_sidebar, steps=6, freq="M")
            fig = px.bar(fc, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", text_auto=True, title="ØªÙˆÙ‚Ø¹ Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª (6 Ø£Ø´Ù‡Ø±)")
            st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹", int(fc["Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©"].sum()))
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(fc, use_container_width=True)

        elif mode.startswith("Ø³Ù†ÙˆÙŠ"):
            if file_yearly_fc.empty:
                st.warning("Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹ ØºÙŠØ± Ø¬Ø§Ù‡Ø².")
            else:
                yrs = [2026, 2027, 2028]
                preds = file_yearly_fc[file_yearly_fc["Ø§Ù„Ø³Ù†Ø©"].isin(yrs)].copy()
                fig = px.bar(preds, x="Ø§Ù„Ø³Ù†Ø©", y="Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)", text_auto=True, title="ØªÙˆÙ‚Ø¹ Ø³Ù†ÙˆÙŠ (Ù…Ù† Ø§Ù„Ù…Ù„Ù)")
                st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (3 Ø³Ù†ÙˆØ§Øª)", int(preds["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"].sum()))
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(preds, use_container_width=True)

        else:
            act = actual_yearly_counts(dff_sidebar)
            cmp_df = compare_actual_vs_file_forecast(act, file_yearly_fc)

            if cmp_df.empty:
                st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©.")
            else:
                long = cmp_df.melt(id_vars="Ø§Ù„Ø³Ù†Ø©",
                                   value_vars=["Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©", "Ø§Ù„Ø§Ø³ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ù…Ù„Ù)"],
                                   var_name="Ø§Ù„Ù†ÙˆØ¹", value_name="Ø§Ù„Ø¹Ø¯Ø¯")
                fig = px.line(long, x="Ø§Ù„Ø³Ù†Ø©", y="Ø§Ù„Ø¹Ø¯Ø¯", color="Ø§Ù„Ù†ÙˆØ¹", markers=True, title="Ù…Ù‚Ø§Ø±Ù†Ø© ÙØ¹Ù„ÙŠ Ã— Ù…ØªÙˆÙ‚Ø¹ (Ù…Ù† Ø§Ù„Ù…Ù„Ù)")
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(cmp_df, use_container_width=True)

with tab4:
    st.markdown("<h1>Ø§Ø³Ø£Ù„Ù†ÙŠ</h1>", unsafe_allow_html=True)
    st.markdown("<p class='small-muted'>Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„â€¦ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ±Ø¯ ÙˆÙŠØ·Ù„Ø¹ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.</p>", unsafe_allow_html=True)

    q = st.chat_input("Ù…Ø«Ø§Ù„: ØªØ±Ù†Ø¯ Ø´Ù‡Ø±ÙŠ | ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª | Ø£ÙƒØ«Ø± Ø¬Ù‡Ø© | ØªÙˆÙ‚Ø¹ 30 ÙŠÙˆÙ… | ØªÙˆÙ‚Ø¹ 2026 | Ø£Ø­Ø¯Ø« Ø³Ø¬Ù„Ø§Øª Ø¬Ø¯ÙˆÙ„")

    if q:
        with st.chat_message("assistant"):
            try:
                msg, fig, table = auto_chart(dff_sidebar, q, top_n=top_n, sidebar_info=sidebar_info)
                st.write(msg)
                if fig is not None:
                    st.plotly_chart(fig, use_container_width=True)
                if table is not None:
                    st.dataframe(table, use_container_width=True)
            except Exception as e:
                st.error("ØµØ§Ø± Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ØŒ Ù„ÙƒÙ† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø´ØºØ§Ù„.")
                st.code(str(e))
    else:
        st.markdown("""
        <div class="welcome-card">
            <h1 style="margin-bottom: 14px;">Ø§Ø³Ø£Ù„Ù†ÙŠ</h1>
            <p style="color:#CBD5E1;font-size:1.15rem;line-height:1.9;max-width:760px;margin:0 auto;">
            Ø£Ù…Ø«Ù„Ø©:
            <br><b>ÙƒÙ… Ø§Ø³ØªÙ‚Ø§Ù„ÙˆØ§ Ø¢Ø®Ø± 3 Ø´Ù‡ÙˆØ±</b> â€” <b>ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª</b> â€” <b>Ø£ÙƒØ«Ø± Ø¬Ù‡Ø©</b> â€” <b>ØªØ±Ù†Ø¯ Ø´Ù‡Ø±ÙŠ</b>
            <br><b>ØªÙˆÙ‚Ø¹ 30 ÙŠÙˆÙ…</b> â€” <b>ØªÙˆÙ‚Ø¹ 6 Ø£Ø´Ù‡Ø±</b> â€” <b>ØªÙˆÙ‚Ø¹ 2026</b> â€” <b>Ø£Ø­Ø¯Ø« Ø³Ø¬Ù„Ø§Øª Ø¬Ø¯ÙˆÙ„</b>
            <br>ÙÙ„ØªØ±Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„: <b>Ø¬Ù‡Ø©: Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©</b> Ø£Ùˆ <b>Ø¬Ù†Ø³ÙŠØ©: Ø³Ø¹ÙˆØ¯ÙŠ</b>
            </p>
        </div>
        """, unsafe_allow_html=True)

if dff_sidebar.empty:
    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ù…Ù† ÙÙ„Ø§ØªØ± Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠØ©. ÙˆØ³Ù‘Ø¹ÙŠ Ø§Ù„ÙØªØ±Ø© Ø£Ùˆ Ø£Ø²ÙŠÙ„ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„ÙÙ„Ø§ØªØ±.")

st.markdown("<div style='text-align:center;color:#94A3B8;margin-top:10px;'>Â© Workforce Intelligence Platform | Dalal Hakami</div>", unsafe_allow_html=True)
